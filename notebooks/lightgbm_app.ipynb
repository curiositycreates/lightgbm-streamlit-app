{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee8324b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-09 01:38:56,119] A new study created in memory with name: no-name-64702bef-cfe5-44d6-b35d-99c13c646a12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haiir\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-07-09 01:38:56,938] Trial 0 finished with value: 2.216043351102563 and parameters: {'learning_rate': 0.012640471492909783, 'num_leaves': 73, 'feature_fraction': 0.625277316903139, 'bagging_fraction': 0.8918250936066789, 'bagging_freq': 5, 'max_depth': 8}. Best is trial 0 with value: 2.216043351102563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 2.21604\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haiir\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-07-09 01:38:57,318] Trial 1 finished with value: 5.80989312408945 and parameters: {'learning_rate': 0.0019369419267920476, 'num_leaves': 64, 'feature_fraction': 0.8784720192281417, 'bagging_fraction': 0.7240732259179166, 'bagging_freq': 5, 'max_depth': 4}. Best is trial 0 with value: 2.216043351102563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 5.80989\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haiir\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-07-09 01:38:57,727] Trial 2 finished with value: 1.885643647047301 and parameters: {'learning_rate': 0.01818391131889043, 'num_leaves': 54, 'feature_fraction': 0.7033177507950659, 'bagging_fraction': 0.7192730798405301, 'bagging_freq': 5, 'max_depth': 6}. Best is trial 2 with value: 1.885643647047301.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[631]\tvalid_0's rmse: 1.88564\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haiir\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-07-09 01:38:58,405] Trial 3 finished with value: 1.850920504352505 and parameters: {'learning_rate': 0.011388545137965646, 'num_leaves': 43, 'feature_fraction': 0.7979879620631398, 'bagging_fraction': 0.673186437452774, 'bagging_freq': 1, 'max_depth': 10}. Best is trial 3 with value: 1.850920504352505.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[900]\tvalid_0's rmse: 1.85092\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haiir\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-07-09 01:38:59,215] Trial 4 finished with value: 6.351979932859768 and parameters: {'learning_rate': 0.0016465945896678704, 'num_leaves': 62, 'feature_fraction': 0.7695092003845663, 'bagging_fraction': 0.7643353656660187, 'bagging_freq': 3, 'max_depth': 12}. Best is trial 3 with value: 1.850920504352505.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 6.35198\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haiir\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-07-09 01:38:59,441] Trial 5 finished with value: 2.124843852327133 and parameters: {'learning_rate': 0.0613206766961608, 'num_leaves': 89, 'feature_fraction': 0.8703810840110188, 'bagging_fraction': 0.8591444554797121, 'bagging_freq': 2, 'max_depth': 12}. Best is trial 3 with value: 1.850920504352505.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's rmse: 2.12484\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haiir\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-07-09 01:38:59,661] Trial 6 finished with value: 1.8505645067481924 and parameters: {'learning_rate': 0.01263584456716943, 'num_leaves': 49, 'feature_fraction': 0.7024410998751933, 'bagging_fraction': 0.7376917714346204, 'bagging_freq': 4, 'max_depth': 3}. Best is trial 6 with value: 1.8505645067481924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[994]\tvalid_0's rmse: 1.85056\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haiir\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-07-09 01:39:00,198] Trial 7 finished with value: 6.057165632982477 and parameters: {'learning_rate': 0.001506020773133794, 'num_leaves': 80, 'feature_fraction': 0.9902534999384769, 'bagging_fraction': 0.6618126638036267, 'bagging_freq': 5, 'max_depth': 5}. Best is trial 6 with value: 1.8505645067481924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 6.05717\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haiir\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-07-09 01:39:00,432] Trial 8 finished with value: 2.1152025186676804 and parameters: {'learning_rate': 0.0544079771077837, 'num_leaves': 77, 'feature_fraction': 0.8313011268850988, 'bagging_fraction': 0.8384434470589537, 'bagging_freq': 2, 'max_depth': 9}. Best is trial 6 with value: 1.8505645067481924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[266]\tvalid_0's rmse: 2.1152\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haiir\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-07-09 01:39:00,991] Trial 9 finished with value: 1.8986805155049433 and parameters: {'learning_rate': 0.014422585551347348, 'num_leaves': 72, 'feature_fraction': 0.9526380576586582, 'bagging_fraction': 0.7551465339715365, 'bagging_freq': 4, 'max_depth': 9}. Best is trial 6 with value: 1.8505645067481924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[664]\tvalid_0's rmse: 1.89868\n",
      "Best RMSE: 1.8505645067481924\n",
      "Best params: {'learning_rate': 0.01263584456716943, 'num_leaves': 49, 'feature_fraction': 0.7024410998751933, 'bagging_fraction': 0.7376917714346204, 'bagging_freq': 4, 'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "# 1. ライブラリ読み込み\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from lightgbm import early_stopping\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "\n",
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"C:\\\\Users\\\\haiir\\\\Documents\\\\python_DIY\\\\Python_Learning\\\\lightgbm-app\")\n",
    "\n",
    "\n",
    "# 2. データ読み込み\n",
    "df = pd.read_csv(\"data/sample_data.csv\")  # パスは適宜調整\n",
    "df.head()\n",
    "\n",
    "# 3. 特徴量と目的変数の分割\n",
    "X = df.drop(columns=[\"fim_out\"])\n",
    "y = df[\"fim_out\"]\n",
    "\n",
    "# 4. 訓練・検証データに分割\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5. Optuna 最適化関数の定義\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 16, 128),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 5),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "    }\n",
    "\n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    dvalid = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "\n",
    "\n",
    "    gbm = lgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    valid_sets=[dvalid],\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[\n",
    "        early_stopping(50),\n",
    "        log_evaluation(0)  # ← 必要に応じて 100 などに変更してもOK\n",
    "    ]\n",
    ")\n",
    "\n",
    "    preds = gbm.predict(X_valid)\n",
    "    rmse = mean_squared_error(y_valid, preds, squared=False)\n",
    "    return rmse\n",
    "\n",
    "# 6. Optuna スタディ実行（軽めに10試行）\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# 7. 結果の確認\n",
    "print(\"Best RMSE:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n",
    "\n",
    "# 8. ベストパラメータでモデル再学習\n",
    "best_params = study.best_params\n",
    "best_params[\"objective\"] = \"regression\"\n",
    "best_params[\"metric\"] = \"rmse\"\n",
    "\n",
    "final_model = lgb.train(\n",
    "    best_params,\n",
    "    lgb.Dataset(X, label=y),\n",
    "    num_boost_round=study.best_trial.number\n",
    ")\n",
    "\n",
    "# 9. モデルを保存\n",
    "import pickle\n",
    "with open(\"models/best_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(final_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2daf769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\haiir\\\\Documents\\\\python_DIY\\\\Python_Learning\\\\lightgbm-app'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bce2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --data DATA [--trials TRIALS] --output\n",
      "                             OUTPUT\n",
      "ipykernel_launcher.py: error: the following arguments are required: --data, --output\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haiir\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import pickle\n",
    "\n",
    "def load_data(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    df.columns = df.columns.str.strip().str.replace(r\"[^\\w]\", \"_\", regex=True)\n",
    "    X = df.drop(columns=[\"fim_out\"])\n",
    "    y = df[\"fim_out\"]\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def objective(trial, X_train, y_train, X_valid, y_valid):\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 16, 128),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 5),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "    }\n",
    "\n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    dvalid = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "    gbm = lgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        valid_sets=[dvalid],\n",
    "        num_boost_round=1000,\n",
    "        callbacks=[early_stopping(50), log_evaluation(0)]\n",
    "    )\n",
    "\n",
    "    preds = gbm.predict(X_valid)\n",
    "    rmse = mean_squared_error(y_valid, preds, squared=False)\n",
    "    return rmse\n",
    "\n",
    "def main(args):\n",
    "    print(f\"📂 Loading data from {args.data} ...\")\n",
    "    X_train, X_valid, y_train, y_valid = load_data(args.data)\n",
    "\n",
    "    print(f\"🔍 Running Optuna with {args.trials} trials...\")\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train, X_valid, y_valid), n_trials=args.trials)\n",
    "\n",
    "    print(\"✅ Best RMSE:\", study.best_value)\n",
    "    print(\"🏆 Best Parameters:\", study.best_params)\n",
    "\n",
    "    print(\"🚀 Training final model on all data...\")\n",
    "    df = pd.read_csv(args.data)\n",
    "    df.columns = df.columns.str.strip().str.replace(r\"[^\\w]\", \"_\", regex=True)\n",
    "    X = df.drop(columns=[\"fim_out\"])\n",
    "    y = df[\"fim_out\"]\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_params[\"objective\"] = \"regression\"\n",
    "    best_params[\"metric\"] = \"rmse\"\n",
    "\n",
    "    final_model = lgb.train(\n",
    "        best_params,\n",
    "        lgb.Dataset(X, label=y),\n",
    "        num_boost_round=study.best_trial.number or 100\n",
    "    )\n",
    "\n",
    "    os.makedirs(os.path.dirname(args.output), exist_ok=True)\n",
    "    with open(args.output, \"wb\") as f:\n",
    "        pickle.dump(final_model, f)\n",
    "\n",
    "    print(f\"💾 Model saved to {args.output}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"LightGBM + Optuna Training Script\")\n",
    "    parser.add_argument(\"--data\", type=str, required=True, help=\"Path to input CSV file\")\n",
    "    parser.add_argument(\"--trials\", type=int, default=10, help=\"Number of Optuna trials\")\n",
    "    parser.add_argument(\"--output\", type=str, required=True, help=\"Path to save the model file\")\n",
    "    args = parser.parse_args()\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18ff46e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(\"C:\\\\Users\\\\haiir\\\\Documents\\\\python_DIY\\\\Python_Learning\\\\lightgbm-app\")\n",
    "df = pd.read_csv(\"data/sample_data.csv\")\n",
    "df.columns = df.columns.str.strip().str.replace(r\"[^\\w]\", \"_\", regex=True)\n",
    "X = df[[\"fim_in\", \"age\", \"mmse\", \"paralysis\"]]\n",
    "y = df[\"fim_out\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f738896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
